#!/bin/bash

set -euo pipefail

basedir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd .. && pwd )"

job_name="${BUILDKITE_PIPELINE_SLUG}-${BUILDKITE_BUILD_NUMBER}-$(head -c 5 /dev/urandom | base32 | tr '[:upper:]' '[:lower:]')"
echo "${job_name}" > /tmp/job_name

if [[ ${BUILDKITE_TIMEOUT:-"false"} == "false" ]]; then
  BUILDKITE_TIMEOUT=600
fi
((timeout=BUILDKITE_TIMEOUT*60))
export BUILDKITE_TIMEOUT

# Default values can be overridden by setting "BUILDKITE_PLUGIN_K8S_*" env vars as used below.
readonly job_apply_loop_interval_seconds="${BUILDKITE_PLUGIN_K8S_JOB_APPLY_LOOP_INTERVAL:-5}"
readonly job_apply_loop_timeout_seconds="${BUILDKITE_PLUGIN_K8S_JOB_APPLY_LOOP_TIMEOUT:-120}"
readonly log_loop_interval_seconds="${BUILDKITE_PLUGIN_K8S_LOG_LOOP_INTERVAL:-3}"
readonly log_loop_attempt_timeout_seconds="${BUILDKITE_PLUGIN_K8S_LOG_LOOP_ATTEMPT_TIMEOUT:-5}"
readonly job_status_loop_sleep_interval="${BUILDKITE_PLUGIN_K8S_JOB_STATUS_LOOP_INTERVAL:-5}"
readonly log_complete_loop_interval_seconds="${BUILDKITE_PLUGIN_K8S_LOG_COMPLETE_LOOP_INTERVAL:-1}"
readonly log_complete_loop_timeout_seconds="${BUILDKITE_PLUGIN_K8S_LOG_COMPLETE_LOOP_TIMEOUT:-30}"
readonly use_agent_node_affinity=${BUILDKITE_PLUGIN_K8S_USE_AGENT_NODE_AFFINITY:-false}
readonly print_resulting_job_spec=${BUILDKITE_PLUGIN_K8S_PRINT_RESULTING_JOB_SPEC:-false}
readonly remove_old_jobs=${BUILDKITE_PLUGIN_K8S_REMOVE_OLD_JOBS:-true}

readonly job_log_complete_marker_file="$(mktemp)"

function cleanup {
  rm -f "$job_log_complete_marker_file"

  if [[ "$remove_old_jobs" == "true" ]]; then
    # Delete all jobs older than a day.
    kubectl delete job "$(kubectl get job -l buildkite/plugin=k8s | awk 'match($4,/[0-9]+d/) {print $1}')" 2>/dev/null || true
  fi
}

trap cleanup EXIT

function tail_logs {
  local log_snapshot=""
  # Once logs are not empty we start attempting to stream them.
  # Keep looping otherwise since empty output means that there is no useful log to display so we're not losing information by looping.
  while true;
  do
    set +e
    log_snapshot="$(timeout "$log_loop_attempt_timeout_seconds" kubectl logs --limit-bytes "1024" "job/${job_name}" 2>/dev/null)"
    set -e
    if [[ -n "$log_snapshot" ]]; then
      break
    fi
    sleep "$log_loop_interval_seconds"
  done

  # Run kubectl logs --follow in a loop since it can fail:
  #   1) It can fail due to pod not being initialized yet: "Error from server (BadRequest): container "step" in pod "somepod" is waiting to start: PodInitializing"
  #   2) It can fail mid-streaming, in this case we unfortunately will display logs multiple times (partially).
  #   3) It can hang not providing any result, that's why we check not only exit code but also contents in the loop above.
  while ! kubectl logs --follow "job/${job_name}" 2>/dev/null;
  do
    sleep "$log_loop_interval_seconds"
  done

  echo "0" > "$job_log_complete_marker_file"
}

echo "--- :kubernetes: Starting Kubernetes Job"

export patchFunc=${BUILDKITE_PLUGIN_K8S_PATCH:-"function(f) f"}

job_spec="$(jsonnet \
  --tla-str "jobName=${job_name}" \
  --tla-str-file "stepEnvFile=${BUILDKITE_ENV_FILE}" \
  --tla-code "agentEnv=$(jq -c -n env)" \
  --tla-code patchFunc \
  "${basedir}/lib/job.jsonnet")"

if [[ "$use_agent_node_affinity" == "true" ]]; then
  for field in affinity tolerations; do
    buildkite_agent_value="$(kubectl get pod "$(cat /etc/hostname)" -o json | jq ".spec.$field")"
    job_spec="$(echo "$job_spec" | jq ".spec.template.spec.$field=$buildkite_agent_value")"
  done
fi

if [[ "$print_resulting_job_spec" == "true" ]]; then
  echo -e "Resulting k8s job spec:\n$job_spec"
fi

readonly job_apply_start_time="$SECONDS"
job_apply_exit_code=""

while [[ "$((SECONDS - job_apply_start_time))" -lt "$job_apply_loop_timeout_seconds" ]]
do
  set +e
  echo "$job_spec" | kubectl apply -f -
  job_apply_exit_code="$?"
  set -e

  if [[ "$job_apply_exit_code" == "0" ]]; then
    break
  else
    echo "Attempt to apply the job failed, exit code '$job_apply_exit_code'"
    sleep "$job_apply_loop_interval_seconds"
  fi
done
echo "Apply job exit code '$job_apply_exit_code'"

echo "Timeout: ${timeout}s"

echo "+++ :kubernetes: Running image: ${BUILDKITE_PLUGIN_K8S_IMAGE}"

tail_logs &

counter=${timeout}
jobstatus=""
while [[ -z "$jobstatus" ]] ; do
  set +e
  jobstatus=$(kubectl get job "${job_name}" -o 'jsonpath={.status.conditions[].type}')
  set -e
  sleep "$job_status_loop_sleep_interval"
  if [[ $timeout -gt 0 ]]; then
    (( counter -= job_status_loop_sleep_interval )) || jobstatus="timeout"
  fi
done

echo "--- :kubernetes: Job status: $jobstatus"

# Wait for logs to be fully printed, printing runs in a separate process and we're racing with it.
readonly log_complete_start_time="$SECONDS"
while [[ "$(cat "$job_log_complete_marker_file")" != "0" ]] && [[ "$((SECONDS - log_complete_start_time))" -lt "$log_complete_loop_timeout_seconds" ]]
do
  sleep "$log_complete_loop_interval_seconds"
done

status=""
if [[ "$jobstatus" == "Complete" ]] ; then
  echo "success"
  status=0
else
  while [[ -z "$status" ]] ; do
    set +e
    pod_name=$(kubectl get pod -l "job-name=$job_name" --output=jsonpath="{.items[*].metadata.name}")
    pod_json=$(kubectl get pod "$pod_name" -o json)
    status="$(echo "$pod_json" | jq ".status.containerStatuses[0].state.terminated.exitCode")"
    set -e
    sleep "$job_status_loop_sleep_interval"
    if [[ $timeout -gt 0 ]]; then
      (( counter -= job_status_loop_sleep_interval )) || status="1"
    fi
  done
fi

exit $status
